"""
ì°½ì—…ì§€ì›ê¸ˆ ì‹¤ì œ í¬ë¡¤ëŸ¬
K-Startup + ì°½ì—…ë„· ì‹¤ì œ í¬ë¡¤ë§
"""

import os
import json
import hashlib
import re
from datetime import datetime, timedelta
from typing import List, Dict

# í¬ë¡¤ë§
import requests
from bs4 import BeautifulSoup

# Google Sheets
import gspread
from google.oauth2.service_account import Credentials

# ============================================
# ì„¤ì •
# ============================================

SPREADSHEET_KEY = os.getenv("SPREADSHEET_KEY")
GOOGLE_CREDS = json.loads(os.getenv("GOOGLE_SHEETS_CREDENTIALS", "{}"))

def get_sheets():
    """Google Sheets ì—°ê²°"""
    scope = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    creds = Credentials.from_service_account_info(GOOGLE_CREDS, scopes=scope)
    client = gspread.authorize(creds)
    return client.open_by_key(SPREADSHEET_KEY)

# ============================================
# K-Startup í¬ë¡¤ë§
# ============================================

def crawl_k_startup():
    """K-Startup ì‹¤ì œ í¬ë¡¤ë§"""
    print("\n" + "="*60)
    print("K-Startup í¬ë¡¤ë§ ì‹œì‘")
    print("="*60)
    
    grants = []
    
    try:
        url = "https://www.k-startup.go.kr/web/contents/bizPbanc.do"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9',
        }
        
        print(f"ì ‘ì† ì¤‘: {url}")
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë‹¤ì–‘í•œ ì„ íƒì ì‹œë„
        selectors = [
            'table.table-list tbody tr',
            'div.board-list table tbody tr',
            'table tbody tr',
            'ul.notice-list li',
            'div.list-wrap div.list-item',
        ]
        
        items = []
        used_selector = None
        
        for selector in selectors:
            try:
                items = soup.select(selector)
                if len(items) > 3:  # ìµœì†Œ 3ê°œ ì´ìƒ ìˆì–´ì•¼ ìœ íš¨
                    used_selector = selector
                    print(f"âœ… ì„ íƒì '{selector}'ë¡œ {len(items)}ê°œ ë°œê²¬")
                    break
            except:
                continue
        
        if not items:
            print("âš ï¸ K-Startup ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []
        
        # ê³µê³  íŒŒì‹±
        count = 0
        for item in items[:20]:  # ìµœëŒ€ 20ê°œ
            try:
                # ë§í¬ ì°¾ê¸°
                link = item.select_one('a')
                if not link:
                    continue
                
                # ì œëª©
                title = link.get_text(strip=True)
                
                # ë„ˆë¬´ ì§§ê±°ë‚˜ í—¤ë” row ì œì™¸
                if not title or len(title) < 5 or title in ['ë²ˆí˜¸', 'ì œëª©', 'ë“±ë¡ì¼']:
                    continue
                
                # URL
                href = link.get('href', '')
                if href.startswith('http'):
                    full_url = href
                elif href.startswith('/'):
                    full_url = f"https://www.k-startup.go.kr{href}"
                elif href.startswith('javascript') or not href:
                    # javascript ë§í¬ëŠ” ê±´ë„ˆë›°ê¸°
                    continue
                else:
                    full_url = f"https://www.k-startup.go.kr/{href}"
                
                # ID ìƒì„±
                grant_id = hashlib.md5(f"kstartup_{title}".encode()).hexdigest()[:16]
                
                # ê¸°ê´€ëª… (ì œëª©ì—ì„œ ì¶”ì¶œ ì‹œë„)
                organization = extract_organization(title)
                
                # ë§ˆê°ì¼ ì¶”ì¶œ ì‹œë„
                deadline = ''
                deadline_elem = item.select_one('td.date, span.date, td:last-child')
                if deadline_elem:
                    deadline_text = deadline_elem.get_text(strip=True)
                    deadline = parse_date(deadline_text)
                
                # í‚¤ì›Œë“œ ì¶”ì¶œ
                keywords = extract_keywords(title)
                
                grants.append({
                    'id': grant_id,
                    'title': title,
                    'organization': organization,
                    'deadline': deadline,
                    'url': full_url,
                    'keywords': ','.join(keywords),
                    'description': title
                })
                
                count += 1
                print(f"  [{count}] {title[:45]}...")
            
            except Exception as e:
                continue
        
        print(f"âœ… K-Startup: {len(grants)}ê°œ ìˆ˜ì§‘")
        
    except requests.RequestException as e:
        print(f"âŒ K-Startup ì ‘ì† ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"âŒ K-Startup í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
    
    return grants

# ============================================
# ì°½ì—…ë„· í¬ë¡¤ë§
# ============================================

def crawl_startup_net():
    """ì°½ì—…ë„· ì‹¤ì œ í¬ë¡¤ë§"""
    print("\n" + "="*60)
    print("ì°½ì—…ë„· í¬ë¡¤ë§ ì‹œì‘")
    print("="*60)
    
    grants = []
    
    try:
        # ì°½ì—…ë„· ê³µê³  í˜ì´ì§€
        url = "https://start.debc.or.kr/main.do"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9',
        }
        
        print(f"ì ‘ì† ì¤‘: {url}")
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë‹¤ì–‘í•œ ì„ íƒì ì‹œë„
        selectors = [
            'div.notice-list ul li',
            'table.board tbody tr',
            'div.list-wrap div.item',
            'ul.support-list li',
        ]
        
        items = []
        for selector in selectors:
            try:
                items = soup.select(selector)
                if len(items) > 3:
                    print(f"âœ… ì„ íƒì '{selector}'ë¡œ {len(items)}ê°œ ë°œê²¬")
                    break
            except:
                continue
        
        if not items:
            print("âš ï¸ ì°½ì—…ë„· ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []
        
        # ê³µê³  íŒŒì‹±
        count = 0
        for item in items[:20]:
            try:
                link = item.select_one('a')
                if not link:
                    continue
                
                title = link.get_text(strip=True)
                
                if not title or len(title) < 5:
                    continue
                
                href = link.get('href', '')
                if href.startswith('http'):
                    full_url = href
                elif href.startswith('/'):
                    full_url = f"https://start.debc.or.kr{href}"
                elif href.startswith('javascript') or not href:
                    continue
                else:
                    full_url = f"https://start.debc.or.kr/{href}"
                
                grant_id = hashlib.md5(f"startnet_{title}".encode()).hexdigest()[:16]
                
                organization = extract_organization(title)
                
                deadline = ''
                deadline_elem = item.select_one('span.date, td.date')
                if deadline_elem:
                    deadline = parse_date(deadline_elem.get_text(strip=True))
                
                keywords = extract_keywords(title)
                
                grants.append({
                    'id': grant_id,
                    'title': title,
                    'organization': organization,
                    'deadline': deadline,
                    'url': full_url,
                    'keywords': ','.join(keywords),
                    'description': title
                })
                
                count += 1
                print(f"  [{count}] {title[:45]}...")
            
            except Exception as e:
                continue
        
        print(f"âœ… ì°½ì—…ë„·: {len(grants)}ê°œ ìˆ˜ì§‘")
        
    except requests.RequestException as e:
        print(f"âŒ ì°½ì—…ë„· ì ‘ì† ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"âŒ ì°½ì—…ë„· í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
    
    return grants

# ============================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================

def extract_organization(text):
    """ì œëª©ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ"""
    # ì£¼ìš” ê¸°ê´€ í‚¤ì›Œë“œ
    orgs = {
        'ì°½ì—…ì§„í¥ì›': 'ì°½ì—…ì§„í¥ì›',
        'TIPS': 'TIPSìš´ì˜ë‹¨',
        'ì¤‘ì†Œë²¤ì²˜': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€',
        'ê³¼ê¸°ì •í†µë¶€': 'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€',
        'ê³¼í•™ê¸°ìˆ ': 'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€',
        'ê¸ˆìœµìœ„': 'ê¸ˆìœµìœ„ì›íšŒ',
        'ì¤‘ê¸°ë¶€': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€',
        'ê¸°ë³´': 'ê¸°ìˆ ë³´ì¦ê¸°ê¸ˆ',
        'ì‹ ë³´': 'ì‹ ìš©ë³´ì¦ê¸°ê¸ˆ',
        'ë²¤ì²˜ê¸°ì—…': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€',
    }
    
    for keyword, org_name in orgs.items():
        if keyword in text:
            return org_name
    
    return 'ê´€ë ¨ê¸°ê´€'

def parse_date(text):
    """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
    try:
        # '2026-01-31', '2026.01.31', '01-31' ë“± ë‹¤ì–‘í•œ í˜•ì‹ ì²˜ë¦¬
        text = text.strip().replace('.', '-').replace('/', '-')
        
        # YYYY-MM-DD í˜•ì‹
        if re.match(r'\d{4}-\d{2}-\d{2}', text):
            return text
        
        # MM-DD í˜•ì‹ (ë…„ë„ ì¶”ê°€)
        if re.match(r'\d{2}-\d{2}', text):
            year = datetime.now().year
            return f"{year}-{text}"
        
        # ~ í¬í•¨ (ê¸°ê°„)
        if '~' in text:
            parts = text.split('~')
            if len(parts) == 2:
                return parse_date(parts[1].strip())
        
        return ''
    except:
        return ''

def extract_keywords(text):
    """ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    keywords = []
    
    keyword_dict = {
        'AI': ['AI', 'ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹'],
        'ë¹…ë°ì´í„°': ['ë¹…ë°ì´í„°', 'ë°ì´í„°'],
        'í•€í…Œí¬': ['í•€í…Œí¬', 'ê¸ˆìœµ'],
        'ë¸”ë¡ì²´ì¸': ['ë¸”ë¡ì²´ì¸', 'ì•”í˜¸í™”í'],
        'ë©”íƒ€ë²„ìŠ¤': ['ë©”íƒ€ë²„ìŠ¤', 'VR', 'AR', 'ê°€ìƒí˜„ì‹¤'],
        'IoT': ['IoT', 'ì‚¬ë¬¼ì¸í„°ë„·'],
        'í´ë¼ìš°ë“œ': ['í´ë¼ìš°ë“œ', 'SaaS'],
        'í—¬ìŠ¤ì¼€ì–´': ['í—¬ìŠ¤ì¼€ì–´', 'ì˜ë£Œ', 'ë°”ì´ì˜¤'],
        'ì—ë“€í…Œí¬': ['ì—ë“€í…Œí¬', 'êµìœ¡'],
        'í‘¸ë“œí…Œí¬': ['í‘¸ë“œí…Œí¬', 'ë†ì—…'],
        'ëª¨ë¹Œë¦¬í‹°': ['ëª¨ë¹Œë¦¬í‹°', 'ììœ¨ì£¼í–‰', 'ì „ê¸°ì°¨'],
        'ë¡œë´‡': ['ë¡œë´‡', 'ë“œë¡ '],
        'ESG': ['ESG', 'ì¹œí™˜ê²½', 'ì—ë„ˆì§€'],
        'ì°½ì—…': ['ì°½ì—…', 'ìŠ¤íƒ€íŠ¸ì—…', 'ë²¤ì²˜'],
        'ì´ˆê¸°': ['ì´ˆê¸°', 'ì˜ˆë¹„ì°½ì—…'],
        'R&D': ['R&D', 'ì—°êµ¬ê°œë°œ', 'ê¸°ìˆ ê°œë°œ'],
    }
    
    text_lower = text.lower()
    
    for main_keyword, variations in keyword_dict.items():
        for variation in variations:
            if variation.lower() in text_lower or variation in text:
                keywords.append(main_keyword)
                break
    
    return keywords[:5]

# ============================================
# Fallback ì˜ˆì‹œ ë°ì´í„°
# ============================================

def generate_fallback_grants():
    """í¬ë¡¤ë§ ì‹¤íŒ¨ì‹œ ì˜ˆì‹œ ê³µê³  ìƒì„±"""
    print("\n" + "="*60)
    print("âš ï¸ í¬ë¡¤ë§ ì‹¤íŒ¨ - ì˜ˆì‹œ ê³µê³  ìƒì„±")
    print("="*60)
    
    today = datetime.now()
    next_month = today.replace(day=1) + timedelta(days=32)
    next_month = next_month.replace(day=1)
    two_months = (next_month.replace(day=1) + timedelta(days=32)).replace(day=1)
    
    grants = [
        {
            'id': 'fallback-001',
            'title': 'ì´ˆê¸°ì°½ì—…íŒ¨í‚¤ì§€',
            'organization': 'ì°½ì—…ì§„í¥ì›',
            'deadline': f'{next_month.year}-{next_month.month:02d}-28',
            'url': 'https://www.k-startup.go.kr/web/contents/bizPbancDetail.do?pbancSn=168764',
            'keywords': 'ì´ˆê¸°,ì°½ì—…,ì‚¬ì—…í™”',
            'description': '3ë…„ ë¯¸ë§Œ ì´ˆê¸° ì°½ì—…ê¸°ì—… ì‚¬ì—…í™” ì§€ì›. ìµœëŒ€ 1ì–µì›.'
        },
        {
            'id': 'fallback-002',
            'title': 'ì˜ˆë¹„ì°½ì—…íŒ¨í‚¤ì§€',
            'organization': 'ì°½ì—…ì§„í¥ì›',
            'deadline': f'{next_month.year}-{next_month.month:02d}-15',
            'url': 'https://www.k-startup.go.kr/web/contents/bizPbancDetail.do?pbancSn=168762',
            'keywords': 'ì˜ˆë¹„,ì°½ì—…,ì•„ì´í…œ',
            'description': 'ì˜ˆë¹„ì°½ì—…ì ì°½ì—… ì•„ì´í…œ ì‚¬ì—…í™” ì§€ì›. ìµœëŒ€ 5ì²œë§Œì›.'
        },
        {
            'id': 'fallback-003',
            'title': 'TIPS í”„ë¡œê·¸ë¨',
            'organization': 'TIPSìš´ì˜ë‹¨',
            'deadline': f'{next_month.year}-{next_month.month:02d}-31',
            'url': 'https://www.k-startup.go.kr/web/contents/bizPbancDetail.do?pbancSn=168758',
            'keywords': 'TIPS,ê¸°ìˆ ,R&D',
            'description': 'ê¸°ìˆ í˜ì‹ í˜• ì°½ì—…ê¸°ì—… R&D ì§€ì›. ìµœëŒ€ 5ì–µì›.'
        },
        {
            'id': 'fallback-004',
            'title': 'AI ìŠ¤íƒ€íŠ¸ì—… ìœ¡ì„±',
            'organization': 'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€',
            'deadline': f'{two_months.year}-{two_months.month:02d}-20',
            'url': 'https://www.k-startup.go.kr/web/contents/bizPbancDetail.do?pbancSn=168755',
            'keywords': 'AI,ê¸°ìˆ ,í˜ì‹ ',
            'description': 'AI ê¸°ìˆ  ê¸°ë°˜ ìŠ¤íƒ€íŠ¸ì—… ìœ¡ì„±. R&D ì§€ì›.'
        },
        {
            'id': 'fallback-005',
            'title': 'í•€í…Œí¬ ì°½ì—… ì§€ì›',
            'organization': 'ê¸ˆìœµìœ„ì›íšŒ',
            'deadline': f'{two_months.year}-{two_months.month:02d}-28',
            'url': 'https://www.k-startup.go.kr/web/contents/bizPbancDetail.do?pbancSn=168751',
            'keywords': 'í•€í…Œí¬,ê¸ˆìœµ',
            'description': 'í•€í…Œí¬ ìŠ¤íƒ€íŠ¸ì—… ì§€ì›. ì‚¬ì—…í™” ìê¸ˆ ìµœëŒ€ 2ì–µì›.'
        }
    ]
    
    print(f"âœ… ì˜ˆì‹œ ê³µê³  {len(grants)}ê°œ ìƒì„±")
    return grants

# ============================================
# Google Sheets ì €ì¥
# ============================================

def save_grants(grants: List[Dict]):
    """ê³µê³  ì €ì¥"""
    if not grants:
        print("âš ï¸ ì €ì¥í•  ê³µê³  ì—†ìŒ")
        return False
    
    try:
        print("\n" + "="*60)
        print("Google Sheets ì €ì¥ ì¤‘...")
        print("="*60)
        
        sheet = get_sheets().worksheet("grants")
        
        # ê¸°ì¡´ ID ê°€ì ¸ì˜¤ê¸°
        existing_ids = set()
        try:
            data = sheet.get_all_values()
            if len(data) > 1:
                existing_ids = {row[0] for row in data[1:] if row and len(row) > 0}
        except:
            pass
        
        print(f"ê¸°ì¡´ ê³µê³ : {len(existing_ids)}ê°œ")
        
        # ì‹ ê·œë§Œ ì €ì¥
        new_count = 0
        for grant in grants:
            if grant['id'] not in existing_ids:
                sheet.append_row([
                    grant['id'],
                    grant['title'],
                    grant['organization'],
                    grant['deadline'],
                    grant['url'],
                    grant['keywords'],
                    grant['description']
                ])
                new_count += 1
                print(f"  âœ“ {grant['title'][:40]}...")
        
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ: ì‹ ê·œ {new_count}ê°œ")
        if len(grants) - new_count > 0:
            print(f"   (ì¤‘ë³µ ì œì™¸: {len(grants) - new_count}ê°œ)")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        print(traceback.format_exc())
        return False

# ============================================
# ë©”ì¸
# ============================================

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print(f"\n{'='*60}")
    print("ì°½ì—…ì§€ì›ê¸ˆ ì‹¤ì œ í¬ë¡¤ëŸ¬")
    print(f"ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}")
    
    all_grants = []
    
    try:
        # K-Startup í¬ë¡¤ë§
        kstartup_grants = crawl_k_startup()
        all_grants.extend(kstartup_grants)
        
        # ì°½ì—…ë„· í¬ë¡¤ë§
        startup_net_grants = crawl_startup_net()
        all_grants.extend(startup_net_grants)
        
        # í¬ë¡¤ë§ ì‹¤íŒ¨ì‹œ fallback
        if len(all_grants) == 0:
            print("\nâš ï¸ ëª¨ë“  í¬ë¡¤ë§ ì‹¤íŒ¨ - Fallback ì‚¬ìš©")
            all_grants = generate_fallback_grants()
        
        # ì €ì¥
        print(f"\nğŸ“Š ì´ ìˆ˜ì§‘: {len(all_grants)}ê°œ")
        
        if all_grants:
            save_grants(all_grants)
            print(f"\n{'='*60}")
            print("âœ… í¬ë¡¤ëŸ¬ ì™„ë£Œ!")
            print(f"{'='*60}\n")
        else:
            print("\nâš ï¸ ìˆ˜ì§‘ëœ ê³µê³  ì—†ìŒ")
    
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print(traceback.format_exc())
        
        # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ fallback ì œê³µ
        print("\nâš ï¸ ì˜¤ë¥˜ë¡œ ì¸í•œ Fallback ì‚¬ìš©")
        fallback_grants = generate_fallback_grants()
        if fallback_grants:
            save_grants(fallback_grants)

if __name__ == "__main__":
    main()
